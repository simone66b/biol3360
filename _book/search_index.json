[["chap8.html", "8 Generalised Least Squares 8.1 Estimation: GLS 8.2 GLS example: Phylogenetic autocorrelation 8.3 GLS example: Phylogenetic autocorrelation 8.4 GLS example: Time Series 8.5 Lynx Data 8.6 ACF and PACF 8.7 Autoregression of Lynx Data 8.8 GLS Autoregression model of Lynx data", " 8 Generalised Least Squares In OLS, the assumption about the errors is that they are independent and identically distributed. What if they are not independent? One common example is that the errors are correlated with each other. Then we have: \\[ \\epsilon \\sim N(0, \\sigma^2 \\mathbf{\\Sigma}) \\] where \\(\\Sigma\\) is a variance-covariance matrix for the residuals. ie \\[ \\mathbf{\\Sigma} = \\begin{bmatrix} \\sigma^2_1 &amp; Cov(\\epsilon_1, \\epsilon_2) &amp; \\cdots &amp; Cov(\\epsilon_1, \\epsilon_n) \\\\ Cov(\\epsilon_2, \\epsilon_1) &amp; \\sigma^2_2 &amp; \\cdots &amp; Cov(\\epsilon_2, \\epsilon_n) \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ Cov(\\epsilon_n, \\epsilon_1) &amp; \\cdots &amp; \\cdots &amp; \\sigma^2_n \\end{bmatrix} \\] 8.1 Estimation: GLS Then we have the GLS Estimator: \\[ \\hat{\\beta_{GLS}} = (\\mathbf{X^T \\Sigma^{-1} X})^{-1}\\mathbf{X^T\\Sigma^{-1}Y} \\] If the covariances (off-diagonals) are zero, then we have weighted least squares We can transform the GLS problem into OLS by multiplying \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) by \\(\\mathbf{\\Sigma}^{-1/2}\\) Then we can use the OLS equation on these new, transformed data. ie, \\(\\mathbf{X^*} = \\mathbf{\\Sigma^{-1/2}X}\\), \\(\\mathbf{Y^*} = \\mathbf{\\Sigma^{-1/2}Y}\\). \\(\\hat{\\beta_{GLS}} = \\mathbf{(X^{*T}X^*)^{-1}X^*Y^*}\\) 8.2 GLS example: Phylogenetic autocorrelation One problem that we have is that the covariances are unknown. Adding more data (the favorite method for statisticians!) does not help, as it just adds more covariances to the problem. We have 2 possible solutions. One, model the covariances using a reduced number of parameters (see the Lynx example below). The other solution is to use additional information from outside of the problem. An example is regression accounting for correlated data due to phylogenetic effects. We will use data from the ade4 package on the body size and home range size of different species of carnivores. The data set also includes a phylogeny for the carnivores. library(ape) ## phylogenetic analyses library(ade4) ## source of data library(ggtree) ## tree ploting functions ## ggtree v3.6.2 For help: https://yulab-smu.top/treedata-book/ ## ## If you use the ggtree package suite in published research, please cite ## the appropriate paper(s): ## ## Guangchuang Yu, David Smith, Huachen Zhu, Yi Guan, Tommy Tsan-Yuk Lam. ## ggtree: an R package for visualization and annotation of phylogenetic ## trees with their covariates and other associated data. Methods in ## Ecology and Evolution. 2017, 8(1):28-36. doi:10.1111/2041-210X.12628 ## ## Guangchuang Yu. Using ggtree to visualize data on tree-like structures. ## Current Protocols in Bioinformatics. 2020, 69:e96. doi:10.1002/cpbi.96 ## ## G Yu. Data Integration, Manipulation and Visualization of Phylogenetic ## Trees (1st ed.). Chapman and Hall/CRC. 2022. ISBN: 9781032233574 ## ## Attaching package: &#39;ggtree&#39; ## The following object is masked from &#39;package:ape&#39;: ## ## rotate data(carni70) ## the data and tree tr &lt;- read.tree(text=carni70$tre) ## extract the tree LogRange &lt;- log(carni70$tab$range) ## log transform LogSize &lt;- log(carni70$tab$size) dat &lt;- data.frame(LogRange=LogRange, LogSize=LogSize, Species=gsub(&quot;_&quot;, &quot;.&quot;, rownames(carni70$tab))) ## set up the data frame ggplot(aes(x=LogSize, y=LogRange), data=dat)+geom_point() ## plot the data ggtree(tr) + geom_tiplab() ## plot the tree 8.3 GLS example: Phylogenetic autocorrelation Here we fit the OLS model and also the GLS model, to compare the results. Note that both models fit a line of best fit, but with different assumptions. We plot the data and the lines on the same graph: library(nlme) ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:ggtree&#39;: ## ## collapse library(ggplot2) fit.lm &lt;- lm(LogRange ~ LogSize, data=dat) ## fit the model using OLS fit.gls &lt;- gls(LogRange ~ LogSize, correlation=corBrownian(phy=tr, form=~Species), data=dat) ## fit the model using GLS summary(fit.lm) ## ## Call: ## lm(formula = LogRange ~ LogSize, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6043 -0.9277 0.3178 1.0636 2.3245 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.3562 0.2123 6.389 1.76e-08 *** ## LogSize 0.2793 0.1070 2.611 0.0111 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.415 on 68 degrees of freedom ## Multiple R-squared: 0.09112, Adjusted R-squared: 0.07776 ## F-statistic: 6.818 on 1 and 68 DF, p-value: 0.0111 summary(fit.gls) ## Generalized least squares fit by REML ## Model: LogRange ~ LogSize ## Data: dat ## AIC BIC logLik ## 294.6851 301.3436 -144.3425 ## ## Correlation Structure: corBrownian ## Formula: ~Species ## Parameter estimate(s): ## numeric(0) ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 1.2515297 2.6279314 0.4762414 0.6354 ## LogSize 0.3710265 0.1950539 1.9021745 0.0614 ## ## Correlation: ## (Intr) ## LogSize -0.16 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -0.7127592 -0.1633996 0.0533231 0.1993733 0.5433174 ## ## Residual standard error: 4.968733 ## Degrees of freedom: 70 total; 68 residual ## construct a function to calculate predicted values for various models predictvals &lt;- function(model, xvar, yvar, xrange=NULL, samples=100,...){ if(is.null(xrange)){ if(class(model) %in% c(&#39;lm&#39;,&#39;glm&#39;)){ xrange= range(model$model[[xvar]]) } else if(class(model) %in% c(&#39;loess&#39;)){ xrange = range(model$x) } } ## construct a new data frame for predictions newdata = data.frame(x = seq(xrange[1], xrange[2], length.out = samples)) names(newdata) = xvar newdata[[yvar]] = predict(model, newdata=newdata, ...) newdata } dat &lt;- data.frame(LogRange = LogRange, LogSize = LogSize) ## Use the predictvals function from &quot;R Graphics Cookbook&quot; ols_predicted &lt;- predictvals(fit.lm, &quot;LogSize&quot;, &quot;LogRange&quot;) ols_predicted$fit &lt;- &quot;OLS&quot; gls_predicted &lt;- predictvals(fit.gls, &quot;LogSize&quot;, &quot;LogRange&quot;, xrange = range(dat$LogSize)) gls_predicted$fit &lt;- &quot;GLS&quot; ggplot(aes(x = LogSize, y = LogRange), data = dat)+ geom_point() + geom_line(aes(x = LogSize, y = LogRange, col = fit), data = ols_predicted, linewidth = 2) + geom_line(aes(x = LogSize, y = LogRange, col = fit), data = gls_predicted, linewidth = 2) plot(fit.gls) qqnorm(fit.gls, form = ~resid(., type = &quot;n&quot;), abline = c(0, 1)) 8.4 GLS example: Time Series Frequently we do not have extra information to specify the covariances among the data points. In that case, an alternative is to model the covariances using a reduced model with fewer parameters. This is what is done using time-series analysis. Time-series analysis is useful when data does not come in all at once, but comes in at a regular rate over time. We expect data that are close by (in time) to be likely to be correlated, and data that are more distant (in time) to be less correlated, or even negatively correlated. There may also be strong positive correlations among data that are distant if there are seasonal effects, for example. A simple example of time-series analysis is the autoregression model: - \\(x_t=\\phi_1x_{t-1}+ \\phi_2x_{t-2} + \\dots + \\phi_px_{t-p}+\\epsilon\\) Here, we model the \\(x_t\\) data at time \\(t\\) by regressing the data on itself at different time lags. The \\(\\phi\\)s represent the strength of the regression relationships and the data at different time lags. The challenge is to estimate the \\(\\phi\\)s and determine how many terms we need to successfully model the data. 8.5 Lynx Data The Lynx data are some of the most famous in ecology. They are the number of lynx (Lynx pardinus: Felidae) pelts collected by Canadian hunters and sold to the Hudson Bay Trading Company over more than 100 years. The data describe cycles of small and large populations of lynx over time. The cause of these cycles has been a popular research topic for many years. data(lynx) str(lynx) ## Time-Series [1:114] from 1821 to 1934: 269 321 585 871 1475 ... lynxdat &lt;- data.frame(Year=1821:1934, Lynx=lynx) ggplot(lynxdat, aes(x=Year, y=Lynx)) + geom_line()+geom_point() + scale_x_continuous() + scale_y_continuous() + ggtitle(&quot;Hudson Bay Lynx Returns&quot;)+theme(plot.title = element_text(hjust = 0.5)) 8.6 ACF and PACF The Autocorrelation Function and the Partial Autocorrelation Function (ACF and PCF) describe the pattern of correlatedness of the data at different time lags. In general significant correlations in the ACF (values that fall above or below the horizontal lines) determines whether you have a problem with temporal autocorrelation. The PACF plot tells you how many \\(\\phi\\) parameters you should use in the analysis. It should be noted that the statistical study of time series is a very large topic and mostly beyond the scope of this course. Nevertheless, GLS is a popular method for simple time series. We see in the following plots that there is indeed a problem with temporal autocorrelation. The ACF shows alternating groups of positive and negative correlations. The PACF suggests that 8 \\(\\phi\\) parameters are needed to model the data, because the largest significant lag is lag number 8. library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## ## Attaching package: &#39;forecast&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## getResponse print(ggAcf(lynx)) print(ggPacf(lynx)) 8.7 Autoregression of Lynx Data We can use the method of Maximum Likelihood Estimation to estimate the \\(\\phi\\) parameters. The ar function estimates that 8 parameters are necessary, and gives the values of the \\(\\phi\\) coefficients. # find optimal autoregression size ar(lynx, method=&quot;mle&quot;) ## ## Call: ## ar(x = lynx, method = &quot;mle&quot;) ## ## Coefficients: ## 1 2 3 4 5 6 7 8 ## 1.0555 -0.6298 0.2105 -0.1438 -0.0200 0.0373 -0.2341 0.3322 ## ## Order selected 8 sigma^2 estimated as 616997 8.8 GLS Autoregression model of Lynx data Next, we can use GLS to fit the time-series model, specifying the number of \\(\\phi\\) parameters as p = 8. fit &lt;- gls(Lynx~Year, correlation=corARMA(p=8), data=lynxdat, method=&quot;ML&quot;) fit ## Generalized least squares fit by maximum likelihood ## Model: Lynx ~ Year ## Data: lynxdat ## Log-likelihood: -923.1686 ## ## Coefficients: ## (Intercept) Year ## -1535.301943 1.657011 ## ## Correlation Structure: ARMA(8,0) ## Formula: ~1 ## Parameter estimate(s): ## Phi1 Phi2 Phi3 Phi4 Phi5 Phi6 ## 1.05436014 -0.62987055 0.20987093 -0.14453853 -0.01997304 0.03578814 ## Phi7 Phi8 ## -0.23275963 0.32892377 ## Degrees of freedom: 114 total; 112 residual ## Residual standard error: 1558.429 Finally, we can re-check the autocorrelation plots of the residuals and verify that there are no further problems with autocorrelation. vals &lt;- resid(fit, type=&quot;n&quot;) print(ggAcf(vals)) print(ggPacf(vals)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
