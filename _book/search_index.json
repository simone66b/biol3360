[["index.html", "BIOL3360 Welcome to BIOL3360!", " BIOL3360 Simone Blomberg Welcome to BIOL3360! "],["chap1.html", "1 BIOL3360: Analysis and Communication of Biological Data 1.1 Course description 1.2 Course Delivery 1.3 Textbooks and Resources 1.4 Assessment 1.5 Goals and expectations 1.6 Course communication 1.7 And finally…", " 1 BIOL3360: Analysis and Communication of Biological Data 1.1 Course description As scientists, we need to be able to collect, analyse and interpret data in terms of statistical and mathematical models. We also need to be able to communicate our findings to other scientists, grant funding bodies, government departments and the general public. This course is designed to give you these skills. We intend that the skills you gain in this course will serve you well in your future careers and studies in biology, or indeed any other field of science. 1.2 Course Delivery The course is designed with three ``modules:’’ Statistical Modelling, Dynamic Modelling and Communication. Statistical Modelling is taught by Simone Blomberg before the mid-semester break. The first three weeks are devoted to gaining R programming skills (no statistics taught in these weeks). Dynamic Modelling is taught by Jan Engelstaedter after the mid-semester break, and the Communication module is run for the entire semester by Louise Kuchel. The course is structured into two ``workshops,’’ one two-hour and one three hour, for a total of 5 contact hours during the week. We expect you to spend another 5 hours on the content outside of contact hours. 1.3 Textbooks and Resources The textbook for R programming will be, The Art of R Programming by Matloff. This is a good introduction which emphasises good programming habits. We will work through several chapters. There is no set textbook for the Statistical Modelling module. However, there are many books which cover the material. My (Simone’s) favorites are: Mixed-Effects Modelling in S and S-PLUS Generalized Linear Models These books will cover the theory. We will discuss the theory and work through examples in R in the workshops. 1.4 Assessment There will be fortnightly quizzes throughout the course, and one ``practical’’ exam for the communication module. There are no mid-semester or final exams. 1.5 Goals and expectations The course can be completed to a high level, if you work diligently. We expect you to come to the workshops (which will not necessarily be recorded). We expect you to prepare for each quiz. We expect you to use your initiative, intelligence, self-discipline, curiosity and vested interest to take responsibility for your own learning. If you start to have trouble, we expect you to ask for help from us, to get you back on track. Feel free to contact any of us by email, but do so sparingly, and be courteous and polite. Ask questions (publicly, privately, anonymously) if you don’t understand a concept. If we can improve something about our teaching or the course, let us know early because we will fix it if we can (SECaTs are good for us and for students next year, but they occur too late to benefit you). If you have a problem, let us know early and propose a solution if possible. 1.6 Course communication We will provide an Ed Discussion Board where you can ask questions of us, and your fellow students, anonymously if need be. Feel free to make an appointment to meet us personally outside of the workshops. We are happy to provide face-to-face advice. Our email addresses are: Simone s.blomberg1@uq.edu.au Jan j.engelstaedter@uq.edu.au Louise l.kuchel@uq.edu.au 1.7 And finally… Good luck with the course! We hope you enjoy it! Simone Blomberg. "],["chap2.html", "2 Week 1: R Programming I 2.1 Why Programming? Why Statistics? Why R? 2.2 Why Statistics? 2.3 Why R?", " 2 Week 1: R Programming I 2.1 Why Programming? Why Statistics? Why R? Computer programming has become an increasingly valued skill for biologists. Computer programming allows us to express complicated ideas in a formal way such that they can be analysed and evaluated using a computer. Thus, the computer “keeps us honest” with regard to our ideas. If we can’t explain our scientific problem to a computer, we haven’t thought it through well enough. Indeed, since Alan Turing showed that a computer can emulate any process that can be described by an algorithm, we might ask, “What are computers for?” Many of you will be used to thinking that computers are used for word processing, spreadsheets, email, Instagram etc. and that is true. But I think the answer to the question goes much deeper than this. The best answer that I can think of is, “Computers are machines for thinking with.” We use computers as an aid to thinking about the world. Computers can take the drudgery out of many scientific processes and leave us with room to think about the “big” questions. Computers are used in many situations in biology. In this course, we will be concerned with using computers to statistically and dynamically model aspects of data and biological processes. 2.2 Why Statistics? The biological world is messy. There is no way we can treat organisms the way atoms and molecules are treated in physics and chemistry. Even if we knew all the physical and chemical properties of all the molecules in an organism, we still could not predict accurately what that organism looks like or how it will behave so we need to use models that incorporate uncertainty and randomness in a principled way. This is why we do statistics. Statistical models have probability “built in.” Statistical models allow us to draw conclusions from data and form a way of thinking about organisms that takes randomness and uncertainty into account. Statistics is at the very heart of biology: the mechanism of natural selection requires that organisms differ, and differences among organisms are ultimately due to the random process of mutation. Mutation is necessary for selection to work. In eukaryotic cells, assortment of chromosomes occur at random, and there can be random “crossing over” events along a chromosome. Thus, statistical models help us to understand how and why organisms have evolved. We will be modelling the properties of data. Data are crucial to the scientific process and it is important to treat them fairly and gently. We will be using a variety of statistical methods to study data. From previous courses, you may be under the impression that statistics is about performing various tests on your data to draw conclusions. It is true that this is one aspect of statistics. But at a more fundamental level, we seek a good model for our data. After obtaining a good model, we find that the statistical tests are easy. They pretty much look after themselves. 2.3 Why R? R is a computer language, similar in many respects to other computer languages that you may have heard of, such as Python, C, and C++. There are many reasons why R is the language of choice for doing statistical modelling. It is free (both free as in “free beer” and free as in “free speech”). It was originally written by statisticians for statisticians so there are many aspects of the language that are ideally suited for doing statistical modelling. The language is relatively easy to read, write, and understand. There are thousands of add-on packages available for R that can be used to do many diverse forms of analysis. R has become the “lingua franca” of statistics. R is used by research statisticians to develop new methods, so chances are that you will have access to the latest methods for doing data analysis. Other packages can take many years to become up to date with well-known methods. Having a good knowledge of programming in R is a skill that employers will find valuable. Even if you don’t end up using R, and instead use some other software, you will find that learning a new system is made much easier because you already have experience with R. Like spoken languages, knowing one language can help you learn another. You can compare and contrast. Often you will find that other systems for statistical analysis are very inferior to R! "],["chap3.html", "3 Beginning R Programming 3.1 The Workspace Setup 3.2 First steps 3.3 The Art of R Programming", " 3 Beginning R Programming 3.1 The Workspace Setup Obtain R from the Comprehensive R Archive Network (CRAN) and install it in the usual way that you install other software. You can use R from the command line in a terminal by typing R (Mac and Linux) or by clicking on the R icon (Windows). However, using R in this way is usually quite tortuous. It is much better to use an Interactive Development Environment (IDE). We shall use RStudio as our IDE. Download and install RStudio from the Posit web site. Make sure you install the free version. After installation, start it up in the usual way for your system. An important point to note: RStudio is not R!. RStudio is merely an interface to R. You should normally not need to cite RStudio in reports etc. Just cite R. To cite R, type citation() at the R prompt. It will output a citation that you can paste into your reports. Open RStudio by clicking on the RStudio icon. A window should pop up with three panes. The pane on the left is the R console. This is where R output will appear. You can also type commands right in there. Minimise the R console and you should see another pane: This is the source pane. You can open new R documents there and edit your code. Make sure you save your code with the extension .R. That will allow RStudio to recognise your R file and give you text coloration and other goodies. The two panes on the left hand side of the window include facilities for examining your workspace environment, viewing plots and help files and a number of other things. Now we are ready to start programming. 3.2 First steps Go to the top-left pane and type. cat(&quot;Hello World!&quot;) Press the run button at the top right of the pane. You should see the output come out in the Console pane. Congratulations! This is your first R program. A “Hello World” program is traditionally the first program a new programmer writes on a new system that they are learning. You have joined the ranks of computer programmers! Some comments about your program: The program calls a function called “cat,” which is a function that prints its arguments in the Console. “cat” stands for “concatenate.” You can use cat() to construct sentences from separate words, as the name suggests. In our case there was only one argument: “Hello World!” so that got printed. “Hello World!” is called a string (short for “character string”). So cat() concatenates strings together. Try: cat(&quot;I said,&quot;, &quot;Hello World!&quot;) You can see that the strings are concatenated and are printed out at the Console. I mentioned that cat() is a function. Functions are the building blocks of computer programs. You will be writing your own functions to do a variety of things. Inside the parentheses, you can put “arguments.” which is what the function works on. These are the inputs to the function. The function can have outputs, called “return values” and functions can also have side-effects. For cat(), the side-effect is to print out something at the Console prompt. The cat() function does not return a value. Functions have definitions. They are what you spend most of the time coding. A typical function definition is: mycat &lt;- function (str) { cat(&quot;This is a&quot;, str) } Notice that we are using the assignment character &lt;- to give a name to the function mycat(). Then follows the keyword function. The body of the function is enclosed within the curly braces. The function calls the cat() function and its argument is str. In this case, as cat() doesn’t return a value, neither will our function. Here is a test: result &lt;- mycat(&quot;dog&quot;) ## This is a dog result ## NULL Note that the function has a side-effect because cat() has a side-effect. (Printing the sentence). Note also that mycat() doesn’t return a value (actually the value NULL which is “nothing” in R.) 3.3 The Art of R Programming I have learned many languages such as: BASIC, Pascal, Lisp, R, MATLAB, and Julia. I also have some knowledge of FORTRAN and C. Mostly, I am self taught. I have found that the best way to learn a new computer language is to do two things. Get a good tutorial book. A good book is your friend. Working through the book will usually teach you everything you need to know, at least at a basic level. You can use the book for reference if you have forgotten how to do things. You can also look up new techniques as you become a better programmer. We use the Art of R Programming because it is a great technical introduction that will give you a good foundation to work from. Have a programming project in mind. This can be as simple or as complex as you want. Although as a raw beginner, you should probably restrict yourself to very simple problems which demonstrate the various aspects and capabilities of the language. I encourage you to think up a project for yourself. You could work on interesting problems that have been raised in other previous courses, or something completely new and different. For example, a game or some piece of usable code that you will use in the future. It’s up to you! We will brainstorm ideas for projects in the workshops. Essentially, we will be having our own mini hackathon. Go to this padlet and post your ideas. Go to “The Art of R Programming” and work through the text up to page 83. This will give you a good grounding in the basics of data types in R: Vectors, matrices, arrays, lists. Work through all the example code: Type it into the top left-hand pane and use the Run button to run your code. While you are reading, consider your own toy problem and how to apply R to it. Alternatively, you could work on this problem, which will give you some practice with R as you read through the chapters: A letter of the alphabet can be considered “odd” if its position in the alphabet is described by an odd number. If it is described by an even number, the letter is “even.” Write an R function that returns the number of odd letters and the number of even letters in a string of arbitrary length. Hint: There is a function called strsplit that you can use to split up a string into its constituent characters. See ?strsplit. "],["chap4.html", "4 More R Programming 4.1 More on Data Structures 4.2 Lists 4.3 Data Frames", " 4 More R Programming 4.1 More on Data Structures Data structures are fundamental to any computer language. You have already seen some: vectors, matrices, and arrays. In fact, matrices and arrays are really special types of vectors. Matrices and arrays have a special property: they possess dimensions. Try this: v &lt;- 1:9 v vmat &lt;- v; dim(vmat) &lt;- c(3, 3) vmat dim(vmat) &lt;- NULL vmat See that you can turn a vector into a matrix, and you can turn a matrix into a vector. The key is the dim() function which allows you to set and get the dimensions of a matrix or vector. The same applies to higher dimensional objects (arrays): avec &lt;- 1:16 arr &lt;- array(avec, c(4, 2, 2)) arr dim(arr) 4.2 Lists Vectors, matrices and arrays are of limited usefulness: they only allow the elements of these data structures to be of the same type. That is, vectors (and matrices and arrays) can only have one type of data in them. For example, you can have a vector of numbers: 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 or a vector of characters: LETTERS[1:10] ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; but you can’t have a vector that mixes characters and numbers: vec &lt;- c(1, &quot;A&quot;) vec ## [1] &quot;1&quot; &quot;A&quot; See that R turns the number (1) into a character (“1”). These are not the same thing! This behaviour may or may not be important to your program but it is crucial that you know about it. So how do you combine, say, characters and numbers? You use another data structure: the list. mylist &lt;- list(1, &quot;A&quot;) mylist ## [[1]] ## [1] 1 ## ## [[2]] ## [1] &quot;A&quot; Here we have a list with two elements. The first element is a numeric vector of length 1. It’s just the number 1. The second element is a character vector of length 1. It is just the character “A.” The way R prints out lists gives us a way to access elements, using the square bracket notation ([[, [, etc). So say we want the first element of mylist. We can do: mylist[[1]] ## [1] 1 Similarly for the second element. (Try it!) Another useful aspect of lists is that the elements can have names: names(mylist) &lt;- c(&quot;Number&quot;, &quot;Letter&quot;) mylist ## $Number ## [1] 1 ## ## $Letter ## [1] &quot;A&quot; mylist$Letter ## [1] &quot;A&quot; See that if the list has named elements, we can use the $ notation. This notation is less general: lists will always have an ordered set of elements but lists don’t always have names attached to the elements. The $ notation is more readable, however. Note also that unlike vectors and matrices, you can have “nested” lists: lists within lists. This is a very useful property in many circumstances: mylist &lt;- list(list(&quot;A&quot;, 1), list(&quot;B&quot;, 2)) mylist ## [[1]] ## [[1]][[1]] ## [1] &quot;A&quot; ## ## [[1]][[2]] ## [1] 1 ## ## ## [[2]] ## [[2]][[1]] ## [1] &quot;B&quot; ## ## [[2]][[2]] ## [1] 2 names(mylist) &lt;- c(&quot;Element1&quot;, &quot;Element2&quot;) mylist ## $Element1 ## $Element1[[1]] ## [1] &quot;A&quot; ## ## $Element1[[2]] ## [1] 1 ## ## ## $Element2 ## $Element2[[1]] ## [1] &quot;B&quot; ## ## $Element2[[2]] ## [1] 2 mylist[[1]][[2]] ## accesses the second element of Element1. ## [1] 1 mylist$Element1[[1]] ## mix and match! ## [1] &quot;A&quot; 4.3 Data Frames A data frame is a special type of list. Its main difference is that a data frame is a list with all its elements having the same length. This is the way that statistical data are usually represented: The columns of the data frame represent variables. The rows of the data frame represent observations. Thus, a data frame is “rectangular.” Here’s a simple example: library(ade4) data(lizards) dat &lt;- lizards$traits head(dat) ## mean.L matur.L max.L hatch.L hatch.m clutch.S age.mat clutch.F ## Sa 69.2 58 82 27.8 0.572 6.0 13 1.5 ## Sh 48.4 42 56 22.9 0.310 3.2 5 2.0 ## Tl 168.4 132 190 42.8 2.235 16.9 19 1.0 ## Mc 66.1 56 72 25.0 0.441 7.2 11 1.5 ## My 70.1 60 81 26.6 0.550 5.4 10 1.0 ## Pb 55.2 44 64 24.0 0.304 4.2 8 2.0 Here we have used the lizards data set from the ade4 package. This data set is actually a list: It has elements traits and two phylogenies: hprA and hprB I extracted the data frame from this list and looked at the first 6 lines. It is a data.frame with 8 variables (columns) and 18 observations, one for each species of lizard in the data set. Since dat is also a list, we can refer to the columns using the square-bracket notation or the $ notation. Also, data frames have another property: they have dimensions: dim(dat) ## [1] 18 8 And you can refer to the elements of the data frame as if they were a matrix: dat[3, 4] ## [1] 42.8 This gives the value at the 3rd row and 4th column. Although each column (variable) has to be of the same length, if you have missing data, you can just put NA which is the missing data character in R: dat[3, 4] &lt;- NA dat[1:4, 1:5] ## mean.L matur.L max.L hatch.L hatch.m ## Sa 69.2 58 82 27.8 0.572 ## Sh 48.4 42 56 22.9 0.310 ## Tl 168.4 132 190 NA 2.235 ## Mc 66.1 56 72 25.0 0.441 Usually you will import data from a file into a data.frame. You can have your NA values in the data file and R will understand them and import them with the rest of the data. "],["chap5.html", "5 Flow of Control 5.1 Loops 5.2 For loops 5.3 while and repeat 5.4 Branching code: The if-then-else construct. 5.5 Conclusion", " 5 Flow of Control Some programs move in a “linear” fashion, from the first statement, to the second, then third etc. until the end of the program is reached. However, most programs (ie functions) that are longer than 3 or 4 lines tend to allow R to jump around the program from one statement to another, but not in a linear order. For example, we may want to repeat a block of statements a large number of times. Or we may want the program to do different things, depending on the state of some variable in the program. 5.1 Loops The most common way of iterating over a block of statements is to use a loop. In R, there are three commands that provide loops, each with its different use. 5.2 For loops The most commonly used loop is the for loop. It is used when you want to iterate several statements over the elements of a vector. A simple example: x &lt;- 1:10 for (i in x) { print(i^2) } ## [1] 1 ## [1] 4 ## [1] 9 ## [1] 16 ## [1] 25 ## [1] 36 ## [1] 49 ## [1] 64 ## [1] 81 ## [1] 100 You can see that the function just prints out the square of the numbers from one to ten, one per line. Although it is most common to iterate over integers (x &lt;- 1:10), we can iterate over the contents of any vector: for (bed in c(&quot;mat&quot;, &quot;sofa&quot;, &quot;table&quot;)) { cat(&quot;The cat sat on the&quot;, bed, &quot;\\n&quot;) } ## The cat sat on the mat ## The cat sat on the sofa ## The cat sat on the table 5.3 while and repeat The next most commonly used loop is a while loop. You go around the loop until some condition is not met. Then you exit the loop and go onto the next statement. Here’s an example: foo &lt;- function () { ## No arguments! cat(&quot;Values from a Normal distribution\\n&quot;) x &lt;- rnorm(1) ## generate a value while (abs(x) &lt; 1.96) { cat(x, &quot;\\n&quot;) ## print x as a side-effect x &lt;- rnorm(1) ## generate a new value } ## go around the loop from here. cat(&quot;Outlier detected:&quot;, x, &quot;\\n&quot;) ## another side-effect } foo() ## call the function. ## Values from a Normal distribution ## 0.4804745 ## 0.9216752 ## 1.303246 ## -0.05150201 ## -0.6151715 ## Outlier detected: 2.414058 Note that the loop occurs while the test condition is TRUE. The flow of control breaks out of the while loop as soon as the test condition is FALSE. You can also break out of loops using the break command. You can also skip an iteration of the loop (usually a for loop) using the next command. The repeat loop is not often used. It simply iterates over a block of code, without the possibility of the loop ending. You can escape from a repeat loop using the break or next commands. 5.4 Branching code: The if-then-else construct. Frequently we want R to make decisions in our code that depend on some criterion. We want our program to change its behaviour depending on this. This is where the if-then-else construct comes in. Here is a simple example: testcat &lt;- function (animal) { if (animal == &quot;cat&quot;) { cat(&quot;Good kitty.\\n&quot;) } else { cat(&quot;What sort of animal are you?\\n&quot;) } } testcat(&quot;cat&quot;) ## Good kitty. testcat(&quot;dog&quot;) ## What sort of animal are you? Here we can see the if-then-else at work. The test criterion is if (animal == \"cat\") then do cat(\"Good kitty.\\n\") else do cat(\"What sort of animal are you?\\n\"). You can see that you don’t actually need to write the then. The if-then-else construct allows us to make programs that branch at one or several places in the code, and execute different blocks of code depending on the test criterion. You can also “chain” if-then-else statements together to test for multiple conditions in the code. 5.5 Conclusion Now we have the building blocks of an R function: We can assign the function a name, and we tell R it is a function using the function key word, followed by the arguments to the function. The main body of the function determines how the arguments are to be treated, which may involve loops or if-else constructs. Finally a value is returned by the function. Along the way, the function might have side-effects such as printing to the screen. "],["chap6.html", "6 LinearModels 6.1 Graphing the Iris data 6.2 Analysing the iris data 6.3 Analysis using t test 6.4 Analysis using ANOVA 6.5 Analysis using Regression 6.6 Points to Note 6.7 Summary 6.8 Linear Models 6.9 Matrix Notation for Linear Models 6.10 Matrix Representation 6.11 Distributional Assumptions 6.12 Estimation: Ordinary Least Squares", " 6 LinearModels Consider R. A. Fisher’s classic Iris data set: knitr::include_graphics(&quot;sepalsPetals.jpg&quot;) Figure 6.1: An Iris knitr::include_graphics(&quot;fisher-smiling-50.jpg&quot;) Figure 6.2: R. A. Fisher data(iris) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa tail(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica knitr::include_graphics(&quot;Kosaciec_szczecinkowaty_Iris_setosa.jpg&quot;) Figure 6.3: Iris setosa knitr::include_graphics(&quot;220px-Iris_virginica.jpg&quot;) Figure 6.4: Iris virginica knitr::include_graphics(&quot;220px-Iris_versicolor_3.jpg&quot;) Figure 6.5: Iris versicolor summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 setosa :50 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 versicolor:50 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 virginica :50 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 6.1 Graphing the Iris data library(ggplot2) ggplot(aes(x = Species, y = Petal.Length), data = iris) + geom_point() + ylim(0, 8) ggplot(aes(x = Species, y = Petal.Length), data = iris) + geom_jitter(width = 0.4, height = 0) + ylim(0, 8) ggplot(aes(x = Species, y = Petal.Length), data = iris) + geom_boxplot() + ylim(0, 8) ## Good Resources for Graphing You can get these books online through the library. R Graphics Cookbook by Chang ggplot2 Elegant Graphics for Data Analysis by Wickham 6.2 Analysing the iris data How would you analyse these data? Analysis of Variance (ANOVA)? fit &lt;- aov(Petal.Length ~ Species, data = iris) summary(fit) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 437.1 218.55 1180 &lt;2e-16 *** ## Residuals 147 27.2 0.19 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Model Diagnostics par(mfrow=c(1,2)) plot(fit, which = 1:2) Subset and Recode the Data} iris2 &lt;- subset(iris, Species != &quot;setosa&quot;) Hypothesis: There exists a difference between the species’ means. How would you analyse these data? - t-test? - ANOVA? - Regression? - All three!!! 6.3 Analysis using t test fit.ttest &lt;- t.test(Petal.Length ~ Species, data = iris2, var.equal = TRUE) print(fit.ttest) ## ## Two Sample t-test ## ## data: Petal.Length by Species ## t = -12.604, df = 98, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0 ## 95 percent confidence interval: ## -1.495426 -1.088574 ## sample estimates: ## mean in group versicolor mean in group virginica ## 4.260 5.552 6.4 Analysis using ANOVA fit.anova &lt;- aov(Petal.Length ~ Species, data = iris2) summary(fit.anova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 1 41.73 41.73 158.9 &lt;2e-16 *** ## Residuals 98 25.74 0.26 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.5 Analysis using Regression fit.regression &lt;- lm(Petal.Length ~ Species, data=iris2) summary(fit.regression) ## ## Call: ## lm(formula = Petal.Length ~ Species, data = iris2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.260 -0.360 0.044 0.340 1.348 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.26000 0.07248 58.77 &lt;2e-16 *** ## Speciesvirginica 1.29200 0.10251 12.60 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5125 on 98 degrees of freedom ## Multiple R-squared: 0.6185, Adjusted R-squared: 0.6146 ## F-statistic: 158.9 on 1 and 98 DF, p-value: &lt; 2.2e-16 6.6 Points to Note For an F test with one degree of freedom in the numerator, \\(F = t^2\\) with the denominator degrees of freedom for the F statistic equal to the degrees of freedom for the t statistic. We can get the regression output from the ANOVA fit using summary.lm summary.lm(fit.anova) ## ## Call: ## aov(formula = Petal.Length ~ Species, data = iris2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.260 -0.360 0.044 0.340 1.348 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.26000 0.07248 58.77 &lt;2e-16 *** ## Speciesvirginica 1.29200 0.10251 12.60 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5125 on 98 degrees of freedom ## Multiple R-squared: 0.6185, Adjusted R-squared: 0.6146 ## F-statistic: 158.9 on 1 and 98 DF, p-value: &lt; 2.2e-16 Regression Plot iris2$coded &lt;- ifelse(iris2$Species == &quot;versicolor&quot;, 0, 1) options(warn = -1) mns &lt;- tapply(iris2$Petal.Length, iris2$coded, mean) df &lt;- data.frame(Petal.Length = mns, coded = 0:1, lower=c(NA, mns[1]), upper = c(NA, mns[2])) ggplot(data=iris2, aes(coded, Petal.Length)) + geom_point() + geom_smooth(method = lm , color = &quot;red&quot;, se = FALSE, formula=y~x) + geom_errorbar(data = df, mapping = aes(x = coded, ymin = lower, ymax = upper), width = 0.05, col = &quot;blue&quot;) + ylim(2.5, 7.5) + xlim(0, 1) + geom_text(label = paste(expression(beta[1])), x = 0.5, y = 4.5, parse = TRUE) + geom_text(label = paste(expression(beta[1])), x = 0.95, y = 5, parse = TRUE) + geom_text(label = paste(expression(beta[0])), x = 0.05, y = 4, parse = TRUE) + geom_text(label = paste(expression(height == beta[0] + beta[1] %*% Species)), x = 0.5, y = 7, parse = TRUE) 6.7 Summary If we code our categorical variables as 0, 1, then the slope \\(\\beta_1\\) is the same as the difference between the means for each category. The intercept \\(\\beta_0\\) is the value for the baseline category. With 3 or more categories, we construct the 0, 1 dummy variables: cat.var &lt;- LETTERS[1:3] model.matrix(~cat.var) ## (Intercept) cat.varB cat.varC ## 1 1 0 0 ## 2 1 1 0 ## 3 1 0 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$cat.var ## [1] &quot;contr.treatment&quot; 6.8 Linear Models Comparing groups or doing regression are examples of the General Linear Model. Regression: \\(y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\epsilon \\sim NID(0, \\sigma^2)\\) ANOVA: \\(y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}, \\epsilon \\sim NID(0, \\sigma^2)\\) Why ``Linear?’’ Definition: A linear transformation (equation) is defined by these 2 properties: – \\(f(x + y) = f(x) + f(y)\\): Additivity – \\(f(Ax) = Af(x)\\) : Homogeneity – Idea: The whole is equal to the sum of its parts. 6.9 Matrix Notation for Linear Models \\(Y_i= \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\epsilon_i \\sim NID(0, \\sigma^2)\\) \\[ Y_1 = \\beta_0 + \\beta_1 X_1 + \\epsilon_1 \\\\ Y_2 = \\beta_0 + \\beta_1 X_2 + \\epsilon_2 \\\\ Y_3 = \\beta_0 + \\beta_1 X_3 + \\epsilon_3 \\\\ \\vdots \\qquad \\vdots \\qquad \\vdots \\\\ Y_n = \\beta_0 + \\beta_1 X_n + \\epsilon_n \\] \\[ \\begin{bmatrix} Y_1 \\\\ Y_2 \\\\ Y_3 \\\\ \\vdots \\\\ Y_n \\end{bmatrix} = \\begin{bmatrix} \\beta_0 + \\beta_1X_1 \\\\ \\beta_0 + \\beta_1X_2 \\\\ \\beta_0 + \\beta_1X_3 \\\\ \\vdots \\\\ \\beta_0 + \\beta_1X_n \\end{bmatrix} + \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix} \\] 6.10 Matrix Representation \\[ \\begin{bmatrix} Y_1 \\\\ Y_2 \\\\ Y_3 \\\\ \\vdots \\\\ Y_n \\end{bmatrix} = \\begin{bmatrix} 1 &amp; X_1 \\\\ 1 &amp; X_2 \\\\ 1 &amp; X_3 \\\\ \\vdots &amp; \\vdots \\\\ 1 &amp; X_n \\end{bmatrix} \\times \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix} \\] \\[ \\mathbf{Y}= \\mathbf{X}\\mathbf{\\beta}+\\mathbf{\\epsilon} \\] 6.11 Distributional Assumptions \\[ \\sigma^2_\\epsilon = \\sigma^2\\mathbf{I} = \\begin{bmatrix} \\sigma^2 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\sigma^2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\sigma^2 \\end{bmatrix} \\] \\[ \\epsilon \\sim N(0, \\sigma^2\\mathbf{I}) \\] Full model: \\(\\textbf{Y} = \\mathbf{X\\beta} + \\mathbf{\\epsilon}, \\quad \\mathbf{\\epsilon} \\sim N(0, \\sigma^2\\mathbf{I})\\) 6.12 Estimation: Ordinary Least Squares \\[ \\hat{\\beta} = (\\mathbf{X^TX})^{-1}\\mathbf{X^T} \\mathbf{Y} \\\\ \\hat{\\sigma^2} = \\frac{1}{n - p}(\\mathbf{Y} - \\mathbf{X\\hat{\\beta}})^T (\\mathbf{Y} - \\mathbf{X\\hat{\\beta}}) \\] where \\(\\hat{\\sigma}^2\\) is the unbiased estimator of \\(\\sigma^2\\), and \\(p=2\\) since we are estimating the slope and the intercept. \\(n\\) is the sample size. "],["chap7.html", "7 Generalised Least Squares 7.1 Estimation: GLS 7.2 GLS example: Phylogenetic autocorrelation 7.3 GLS example: Phylogenetic autocorrelation 7.4 GLS example: Time Series 7.5 Lynx Data 7.6 ACF and PACF 7.7 Autoregression of Lynx Data 7.8 GLS Autoregression model of Lynx data", " 7 Generalised Least Squares In OLS, the assumption about the errors is that they are independent and identically distributed. What if they are not independent? One common example is that the errors are correlated with each other. Then we have: \\[ \\epsilon \\sim N(0, \\sigma^2 \\mathbf{\\Sigma}) \\] where \\(\\Sigma\\) is a variance-covariance matrix for the residuals. ie \\[ \\mathbf{\\Sigma} = \\begin{bmatrix} \\sigma^2_1 &amp; Cov(\\epsilon_1, \\epsilon_2) &amp; \\cdots &amp; Cov(\\epsilon_1, \\epsilon_n) \\\\ Cov(\\epsilon_2, \\epsilon_1) &amp; \\sigma^2_2 &amp; \\cdots &amp; Cov(\\epsilon_2, \\epsilon_n) \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ Cov(\\epsilon_n, \\epsilon_1) &amp; \\cdots &amp; \\cdots &amp; \\sigma^2_n \\end{bmatrix} \\] 7.1 Estimation: GLS Then we have the GLS Estimator: \\[ \\hat{\\beta_{GLS}} = (\\mathbf{X^T \\Sigma^{-1} X})^{-1}\\mathbf{X^T\\Sigma^{-1}Y} \\] If the covariances (off-diagonals) are zero, then we have weighted least squares We can transform the GLS problem into OLS by multiplying \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) by \\(\\mathbf{\\Sigma}^{-1/2}\\) Then we can use the OLS equation on these new, transformed data. ie, \\(\\mathbf{X^*} = \\mathbf{\\Sigma^{-1/2}X}\\), \\(\\mathbf{Y^*} = \\mathbf{\\Sigma^{-1/2}Y}\\). \\(\\hat{\\beta_{GLS}} = \\mathbf{(X^{*T}X^*)^{-1}X^*Y^*}\\) 7.2 GLS example: Phylogenetic autocorrelation library(ape) library(ade4) library(ggtree) ## ggtree v3.6.2 For help: https://yulab-smu.top/treedata-book/ ## ## If you use the ggtree package suite in published research, please cite the appropriate ## paper(s): ## ## Guangchuang Yu, David Smith, Huachen Zhu, Yi Guan, Tommy Tsan-Yuk Lam. ggtree: an R package ## for visualization and annotation of phylogenetic trees with their covariates and other ## associated data. Methods in Ecology and Evolution. 2017, 8(1):28-36. ## doi:10.1111/2041-210X.12628 ## ## Guangchuang Yu. Using ggtree to visualize data on tree-like structures. Current Protocols in ## Bioinformatics. 2020, 69:e96. doi:10.1002/cpbi.96 ## ## Guangchuang Yu, Tommy Tsan-Yuk Lam, Huachen Zhu, Yi Guan. Two methods for mapping and ## visualizing associated data on phylogeny using ggtree. Molecular Biology and Evolution. ## 2018, 35(12):3041-3043. doi:10.1093/molbev/msy194 ## ## Attaching package: &#39;ggtree&#39; ## The following object is masked from &#39;package:ape&#39;: ## ## rotate data(carni70) tr &lt;- read.tree(text=carni70$tre) LogRange &lt;- log(carni70$tab$range) LogSize &lt;- log(carni70$tab$size) dat &lt;- data.frame(LogRange=LogRange, LogSize=LogSize, Species=gsub(&quot;_&quot;, &quot;.&quot;, rownames(carni70$tab))) ggplot(aes(x=LogSize, y=LogRange), data=dat)+geom_point() ggtree(tr) + geom_tiplab() 7.3 GLS example: Phylogenetic autocorrelation library(nlme) ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:ggtree&#39;: ## ## collapse fit.lm &lt;- lm(LogRange ~ LogSize, data=dat) fit.gls &lt;- gls(LogRange ~ LogSize, correlation=corBrownian(phy=tr, form=~Species), data=dat) summary(fit.lm) ## ## Call: ## lm(formula = LogRange ~ LogSize, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6043 -0.9277 0.3178 1.0636 2.3245 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.3562 0.2123 6.389 1.76e-08 *** ## LogSize 0.2793 0.1070 2.611 0.0111 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.415 on 68 degrees of freedom ## Multiple R-squared: 0.09112, Adjusted R-squared: 0.07776 ## F-statistic: 6.818 on 1 and 68 DF, p-value: 0.0111 summary(fit.gls) ## Generalized least squares fit by REML ## Model: LogRange ~ LogSize ## Data: dat ## AIC BIC logLik ## 294.6851 301.3436 -144.3425 ## ## Correlation Structure: corBrownian ## Formula: ~Species ## Parameter estimate(s): ## numeric(0) ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 1.2515297 2.6279314 0.4762414 0.6354 ## LogSize 0.3710265 0.1950539 1.9021745 0.0614 ## ## Correlation: ## (Intr) ## LogSize -0.16 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -0.7127592 -0.1633996 0.0533231 0.1993733 0.5433174 ## ## Residual standard error: 4.968733 ## Degrees of freedom: 70 total; 68 residual predictvals &lt;- function(model, xvar, yvar, xrange=NULL, samples=100,...){ if(is.null(xrange)){ if(class(model) %in% c(&#39;lm&#39;,&#39;glm&#39;)){ xrange= range(model$model[[xvar]]) } else if(class(model) %in% c(&#39;loess&#39;)){ xrange = range(model$x) } } newdata = data.frame(x = seq(xrange[1], xrange[2], length.out = samples)) names(newdata) = xvar newdata[[yvar]] = predict(model, newdata=newdata, ...) newdata } dat &lt;- data.frame(LogRange = LogRange, LogSize = LogSize) ## Use the predictvals function from &quot;R Graphics Cookbook&quot; ols_predicted &lt;- predictvals(fit.lm, &quot;LogSize&quot;, &quot;LogRange&quot;) ols_predicted$fit &lt;- &quot;OLS&quot; gls_predicted &lt;- predictvals(fit.gls, &quot;LogSize&quot;, &quot;LogRange&quot;, xrange = range(dat$LogSize)) gls_predicted$fit &lt;- &quot;GLS&quot; ggplot(aes(x = LogSize, y = LogRange), data = dat)+ geom_point() + geom_line(aes(x = LogSize, y = LogRange, col = fit), data = ols_predicted, linewidth = 2) + geom_line(aes(x = LogSize, y = LogRange, col = fit), data = gls_predicted, linewidth = 2) plot(fit.gls) qqnorm(fit.gls, form = ~resid(., type = &quot;n&quot;), abline = c(0, 1)) 7.4 GLS example: Time Series We expect that adjacent values may be more similar than values further away in time. That is, the effect of the disturbance on the time series decays with time. In general we do not know the covariances of each value with all other values. Instead, we can model the time series effects using a smaller number of parameters. A simple example is the autoregression model: \\(x_t=\\phi_1x_{t-1}+ \\phi_2x_{t-2} + \\dots + \\phi_px_{t-p}+\\epsilon\\) 7.5 Lynx Data data(lynx) str(lynx) ## Time-Series [1:114] from 1821 to 1934: 269 321 585 871 1475 ... lynxdat &lt;- data.frame(Year=1821:1934, Lynx=lynx) ggplot(lynxdat, aes(x=Year, y=Lynx)) + geom_line()+geom_point() + scale_x_continuous() + scale_y_continuous() + ggtitle(&quot;Hudson Bay Lynx Returns&quot;)+theme(plot.title = element_text(hjust = 0.5)) 7.6 ACF and PACF library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## ## Attaching package: &#39;forecast&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## getResponse print(ggAcf(lynx)) print(ggPacf(lynx)) 7.7 Autoregression of Lynx Data # find optimal autoregression size ar(lynx, method=&quot;mle&quot;) ## ## Call: ## ar(x = lynx, method = &quot;mle&quot;) ## ## Coefficients: ## 1 2 3 4 5 6 7 8 ## 1.0555 -0.6298 0.2105 -0.1438 -0.0200 0.0373 -0.2341 0.3322 ## ## Order selected 8 sigma^2 estimated as 616997 7.8 GLS Autoregression model of Lynx data fit &lt;- gls(Lynx~Year, correlation=corARMA(p=8), data=lynxdat, method=&quot;ML&quot;) fit ## Generalized least squares fit by maximum likelihood ## Model: Lynx ~ Year ## Data: lynxdat ## Log-likelihood: -923.1686 ## ## Coefficients: ## (Intercept) Year ## -1535.301943 1.657011 ## ## Correlation Structure: ARMA(8,0) ## Formula: ~1 ## Parameter estimate(s): ## Phi1 Phi2 Phi3 Phi4 Phi5 Phi6 Phi7 Phi8 ## 1.05436014 -0.62987055 0.20987093 -0.14453853 -0.01997304 0.03578814 -0.23275963 0.32892377 ## Degrees of freedom: 114 total; 112 residual ## Residual standard error: 1558.429 vals &lt;- resid(fit, type=&quot;n&quot;) print(ggAcf(vals)) print(ggPacf(vals)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
